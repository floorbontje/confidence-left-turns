{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import interpolate, optimize\n",
    "import ddm\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossWLS(ddm.LossFunction):\n",
    "    name = 'Weighted least squares as described in Ratcliff & Tuerlinckx 2002'\n",
    "    rt_quantiles = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    rt_q_weights = [2, 2, 1, 1, 0.5]\n",
    "#     exp_data = pd.read_csv('../data/measures.csv', \n",
    "#                             usecols=['subj_id', 'RT', 'is_turn_decision', 'tta_condition', 'd_condition'])\n",
    "           \n",
    "    def setup(self, dt, T_dur, **kwargs):\n",
    "        self.dt = dt\n",
    "        self.T_dur = T_dur\n",
    "    \n",
    "    def get_rt_quantiles(self, x, t_domain, exp=False):\n",
    "        cdf = x.cdf_corr(T_dur=self.T_dur, dt=self.dt) if exp else x.cdf_corr()\n",
    "        cdf_interp = interpolate.interp1d(t_domain, cdf/cdf[-1])\n",
    "        # If the model produces very fast RTs, interpolated cdf(0) can be >0.1, then we cannot find root like usual\n",
    "        # In this case, the corresponding rt quantile is half of the time step of cdf\n",
    "        rt_quantile_values = [optimize.root_scalar(lambda x:cdf_interp(x)-quantile, bracket=(0, t_domain[-1])).root\n",
    "                              if (cdf_interp(0)<quantile) else self.dt/2\n",
    "                              for quantile in self.rt_quantiles]\n",
    "        return np.array(rt_quantile_values)\n",
    "    \n",
    "    def loss(self, model):\n",
    "        solultions = self.cache_by_conditions(model)\n",
    "        WLS = 0\n",
    "        for comb in self.sample.condition_combinations(required_conditions=self.required_conditions):\n",
    "            c = frozenset(comb.items())\n",
    "            comb_sample = self.sample.subset(**comb)\n",
    "            WLS += 4*(solultions[c].prob_correct() - comb_sample.prob_correct())**2            \n",
    "            # Sometimes model p_correct is very close to 0, then RT distribution is weird, in this case ignore RT error \n",
    "            if ((solultions[c].prob_correct()>0.001) & (comb_sample.prob_correct()>0)):\n",
    "#                 self.condition_data = self.exp_data[(self.exp_data.d_condition==comb['d_condition']) \n",
    "#                                                     & (self.exp_data.tta_condition==comb['tta_condition'])]\n",
    "#                 self.condition_data = list(comb_sample.items(correct=True))\n",
    "                model_rt_q = self.get_rt_quantiles(solultions[c], model.t_domain(), exp=False)\n",
    "                exp_rt_q = self.get_rt_quantiles(comb_sample, model.t_domain(), exp=True)\n",
    "                WLS += np.dot((model_rt_q-exp_rt_q)**2, self.rt_q_weights)*comb_sample.prob_correct()\n",
    "        return WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_dur = 2.5\n",
    "\n",
    "class DriftTtaDistance(ddm.models.Drift):\n",
    "    name = 'Drift depends on TTA and distance'\n",
    "    required_parameters = ['alpha', 'tta_crit', 'beta', 'd_crit']\n",
    "    required_conditions = ['tta_condition', 'd_condition'] \n",
    "    \n",
    "    def get_drift(self, t, conditions, **kwargs):\n",
    "        v = conditions['d_condition']/conditions['tta_condition']\n",
    "        return (self.alpha*(conditions['tta_condition'] - t - self.tta_crit + \n",
    "                            self.beta*(conditions['d_condition'] - v*t - self.d_crit)))\n",
    "\n",
    "class BoundCollapsingTta(ddm.models.Bound):\n",
    "    name = 'Bounds collapsing with TTA'\n",
    "    required_parameters = ['b_0', 'k', 'tta_crit']\n",
    "    required_conditions = ['tta_condition'] \n",
    "    def get_bound(self, t, conditions, **kwargs):\n",
    "        tau = conditions['tta_condition'] - t\n",
    "        return self.b_0/(1+np.exp(-self.k*(tau-self.tta_crit)))\n",
    "\n",
    "param_names = ['alpha', 'tta_crit', 'beta', 'd_crit', 'noise', 'b_0', 'k', 'tta_crit', 'nondectime', 'halfwidth']\n",
    "tta_crit = ddm.Fittable(minval=3, maxval=6)\n",
    "model_TTA_bounds = ddm.Model(name='5 TTA- and d-dependent drift and bounds and uniformly distributed nondecision time',\n",
    "                             drift=DriftTtaDistance(alpha=ddm.Fittable(minval=0.1, maxval=3),\n",
    "                                                     tta_crit=tta_crit,\n",
    "                                                     beta=ddm.Fittable(minval=0, maxval=1),\n",
    "                                                     d_crit=ddm.Fittable(minval=90, maxval=150)),\n",
    "                             noise=ddm.NoiseConstant(noise=1),\n",
    "                             bound=BoundCollapsingTta(b_0=ddm.Fittable(minval=0.5, maxval=5), \n",
    "                                                      k=ddm.Fittable(minval=0.1, maxval=2),\n",
    "                                                      tta_crit=tta_crit),\n",
    "                             overlay=ddm.OverlayNonDecisionUniform(nondectime=ddm.Fittable(minval=0, maxval=0.5),\n",
    "                                                                   halfwidth=ddm.Fittable(minval=0, maxval=0.3)),\n",
    "                             T_dur=T_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, exp_data, subj_id):\n",
    "    print(subj_id)\n",
    "    training_data = exp_data[(exp_data.subj_id == subj_id)] \n",
    "#                              & ~((exp_data.d_condition==condition['d']) & (exp_data.tta_condition==condition['tta']))]\n",
    "    training_sample = ddm.Sample.from_pandas_dataframe(df=training_data, \n",
    "                                                       rt_column_name='RT', correct_column_name='is_turn_decision')\n",
    "    return(ddm.fit_adjust_model(sample=training_sample, model=model, lossfunction=LossWLS, suppress_output=True))\n",
    "\n",
    "def write_to_csv(directory, filename, array):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(os.path.join(directory, filename), 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_TTA_bounds\n",
    "\n",
    "exp_data = pd.read_csv('../data/measures.csv', usecols=['subj_id', 'RT', 'is_turn_decision', \n",
    "                                                        'tta_condition', 'd_condition'])\n",
    "subjects = exp_data.subj_id.unique()\n",
    "# conditions = [{'tta': tta, 'd': d} \n",
    "#                   for tta in exp_data.tta_condition.unique() \n",
    "#                   for d in exp_data.d_condition.unique()]\n",
    "\n",
    "directory = '../model_fit_results/'\n",
    "write_to_csv(directory, 'model_%s_params_by_subject.csv' % (model.name[0]), \n",
    "             ['subj_id', 'i', 'loss'] + param_names)\n",
    "\n",
    "for subj_id in subjects:\n",
    "#     for condition in conditions:\n",
    "    for i in range(5):\n",
    "        fitted_model = fit_model(model, exp_data, subj_id)\n",
    "        write_to_csv(directory, 'model_%s_params_by_subject.csv' % (model.name[0]), \n",
    "                     [subj_id, i, fitted_model.get_fit_result().value()] \n",
    "                     + fitted_model.get_model_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
